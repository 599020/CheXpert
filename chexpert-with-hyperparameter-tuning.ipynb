{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1618416,"sourceType":"datasetVersion","datasetId":955838}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Importing the fastai libary for image recognition and others used in the model","metadata":{}},{"cell_type":"code","source":"from fastai.vision.all import *\nfrom torchvision.models import *\nfrom pathlib import Path\n\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F","metadata":{"execution":{"iopub.status.busy":"2024-04-21T19:13:22.487952Z","iopub.execute_input":"2024-04-21T19:13:22.488857Z","iopub.status.idle":"2024-04-21T19:13:22.495095Z","shell.execute_reply.started":"2024-04-21T19:13:22.488821Z","shell.execute_reply":"2024-04-21T19:13:22.494096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here I create paths to the different data in my dataset","metadata":{}},{"cell_type":"code","source":"data_path = Path('/kaggle/input/chexpert')\npath_train = Path('/kaggle/input/chexpert/CheXpert-v1.0-small/train')\npath_valid = Path('/kaggle/input/chexpert/CheXpert-v1.0-small/valid')","metadata":{"execution":{"iopub.status.busy":"2024-04-21T19:13:22.497485Z","iopub.execute_input":"2024-04-21T19:13:22.498124Z","iopub.status.idle":"2024-04-21T19:13:22.505981Z","shell.execute_reply.started":"2024-04-21T19:13:22.498091Z","shell.execute_reply":"2024-04-21T19:13:22.505222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Gets the csv files for training and validation","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv(data_path/'CheXpert-v1.0-small/train.csv')\nvalid_df = pd.read_csv(data_path/'CheXpert-v1.0-small/valid.csv')","metadata":{"execution":{"iopub.status.busy":"2024-04-21T19:13:22.506965Z","iopub.execute_input":"2024-04-21T19:13:22.507250Z","iopub.status.idle":"2024-04-21T19:13:23.055333Z","shell.execute_reply.started":"2024-04-21T19:13:22.507227Z","shell.execute_reply":"2024-04-21T19:13:23.054509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Looking at what the csv files are containing ","metadata":{}},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-21T19:13:23.056468Z","iopub.execute_input":"2024-04-21T19:13:23.056771Z","iopub.status.idle":"2024-04-21T19:13:23.080385Z","shell.execute_reply.started":"2024-04-21T19:13:23.056746Z","shell.execute_reply":"2024-04-21T19:13:23.079483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-21T19:13:23.082828Z","iopub.execute_input":"2024-04-21T19:13:23.083351Z","iopub.status.idle":"2024-04-21T19:13:23.112074Z","shell.execute_reply.started":"2024-04-21T19:13:23.083327Z","shell.execute_reply":"2024-04-21T19:13:23.111180Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Exploring the data for NaN values","metadata":{}},{"cell_type":"code","source":"train_df.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2024-04-21T19:13:23.113174Z","iopub.execute_input":"2024-04-21T19:13:23.113504Z","iopub.status.idle":"2024-04-21T19:13:23.206674Z","shell.execute_reply.started":"2024-04-21T19:13:23.113479Z","shell.execute_reply":"2024-04-21T19:13:23.205855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_df.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2024-04-21T19:13:23.207604Z","iopub.execute_input":"2024-04-21T19:13:23.207852Z","iopub.status.idle":"2024-04-21T19:13:23.215245Z","shell.execute_reply.started":"2024-04-21T19:13:23.207831Z","shell.execute_reply":"2024-04-21T19:13:23.214270Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Making a list of the targets we are looking to find","metadata":{}},{"cell_type":"code","source":"    chexnet_targets = ['No Finding', 'Enlarged Cardiomediastinum', 'Cardiomegaly', 'Lung Opacity', 'Lung Lesion', 'Edema', 'Consolidation', 'Pneumonia', 'Atelectasis', 'Pneumothorax', 'Pleural Effusion', 'Pleural Other', 'Fracture', 'Support Devices']","metadata":{"execution":{"iopub.status.busy":"2024-04-21T19:13:23.216412Z","iopub.execute_input":"2024-04-21T19:13:23.216723Z","iopub.status.idle":"2024-04-21T19:13:23.224668Z","shell.execute_reply.started":"2024-04-21T19:13:23.216695Z","shell.execute_reply":"2024-04-21T19:13:23.223870Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Handles the NaN values by filling them in with the value 0, and making any uncertain answers to 1 (this is not the best solution but the one we got time for, when working with this project later this will be a focus point in making a better model)","metadata":{}},{"cell_type":"code","source":"train_df = train_df.fillna(0)\ntrain_df[chexnet_targets] = train_df[chexnet_targets].abs()","metadata":{"execution":{"iopub.status.busy":"2024-04-21T19:13:23.225846Z","iopub.execute_input":"2024-04-21T19:13:23.226173Z","iopub.status.idle":"2024-04-21T19:13:23.395061Z","shell.execute_reply.started":"2024-04-21T19:13:23.226140Z","shell.execute_reply":"2024-04-21T19:13:23.393670Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_df = valid_df.fillna(0)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T19:13:23.396642Z","iopub.execute_input":"2024-04-21T19:13:23.397008Z","iopub.status.idle":"2024-04-21T19:13:23.402639Z","shell.execute_reply.started":"2024-04-21T19:13:23.396974Z","shell.execute_reply":"2024-04-21T19:13:23.401649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Look over the data after filling in NaN values and converting the -1 values to 1","metadata":{}},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-21T19:13:23.403828Z","iopub.execute_input":"2024-04-21T19:13:23.404089Z","iopub.status.idle":"2024-04-21T19:13:23.437577Z","shell.execute_reply.started":"2024-04-21T19:13:23.404065Z","shell.execute_reply":"2024-04-21T19:13:23.436763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-21T19:13:23.438539Z","iopub.execute_input":"2024-04-21T19:13:23.438811Z","iopub.status.idle":"2024-04-21T19:13:23.464937Z","shell.execute_reply.started":"2024-04-21T19:13:23.438788Z","shell.execute_reply":"2024-04-21T19:13:23.463948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Making the functions for getting the pictures path (get_x) that will be used by our vision learner\n\nMaking the function for finding wich condition the patient has (get_y)","metadata":{}},{"cell_type":"code","source":"def get_x(row): \n    return data_path / row['Path']\n\ndef get_y(row):\n    condition_columns = ['No Finding', 'Enlarged Cardiomediastinum', 'Cardiomegaly', 'Lung Opacity', 'Lung Lesion', 'Edema', 'Consolidation', 'Pneumonia', 'Atelectasis', 'Pneumothorax', 'Pleural Effusion', 'Pleural Other', 'Fracture', 'Support Devices']\n    labels = [i for i in condition_columns if row[i]== 1]\n    return labels","metadata":{"execution":{"iopub.status.busy":"2024-04-21T19:13:23.466089Z","iopub.execute_input":"2024-04-21T19:13:23.466426Z","iopub.status.idle":"2024-04-21T19:13:23.474250Z","shell.execute_reply.started":"2024-04-21T19:13:23.466395Z","shell.execute_reply":"2024-04-21T19:13:23.473400Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Combining the csv files into one singular csv file, but making sure to mark what was in the validation set so that we can use this later","metadata":{}},{"cell_type":"code","source":"combined_df = pd.concat([train_df, valid_df], ignore_index=True)\n\nvalid_idx_start = len(train_df)\n\nvalid_idx = list(range(valid_idx_start, len(combined_df)))","metadata":{"execution":{"iopub.status.busy":"2024-04-21T19:13:23.478052Z","iopub.execute_input":"2024-04-21T19:13:23.478377Z","iopub.status.idle":"2024-04-21T19:13:23.503615Z","shell.execute_reply.started":"2024-04-21T19:13:23.478353Z","shell.execute_reply":"2024-04-21T19:13:23.502730Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Making the datablock that will be used later","metadata":{}},{"cell_type":"code","source":"datablock = DataBlock(\n    blocks = (ImageBlock, MultiCategoryBlock),\n    splitter = IndexSplitter(valid_idx),\n    get_x = get_x,\n    get_y = get_y,\n    item_tfms = Resize(256),\n    batch_tfms = aug_transforms(size=224, min_scale=0.75)\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T19:13:23.504633Z","iopub.execute_input":"2024-04-21T19:13:23.504913Z","iopub.status.idle":"2024-04-21T19:13:23.512015Z","shell.execute_reply.started":"2024-04-21T19:13:23.504889Z","shell.execute_reply":"2024-04-21T19:13:23.511061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_dataloaders(batch_size):\n    # Definer DataBlock og dataloaders her basert på ditt datasett\n    # For eksempel:\n    datablock = DataBlock(\n        blocks=(ImageBlock, MultiCategoryBlock),\n        splitter=IndexSplitter(valid_idx),  # Juster splitteren etter behov\n        get_x=get_x,\n        get_y=get_y,\n        item_tfms=Resize(256),\n        batch_tfms=aug_transforms(size=224, min_scale=0.75)\n    )\n\n    dls = datablock.dataloaders(combined_df, bs=batch_size)\n    return dls\n\ndef create_model(num_layers):\n    # Opprett modellen basert på ønsket arkitektur (f.eks. resnet) og num_layers\n    if num_layers == 18:\n        model = resnet18(pretrained=True)\n    elif num_layers == 34:\n        model = resnet34(pretrained=True)\n    elif num_layers == 50:\n        model = resnet50(pretrained=True)\n    else:\n        raise ValueError(\"Ugyldig num_layers valgt\")\n\n    # Tilpasninger av modellen kan legges til her hvis nødvendig\n    # For eksempel: Tilpasning av siste lag for antall klasser i ditt datasett\n    num_classes = len(dls.vocab)\n    model.fc = nn.Linear(model.fc.in_features, num_classes)\n\n    return model\n","metadata":{"execution":{"iopub.status.busy":"2024-04-21T19:13:23.513232Z","iopub.execute_input":"2024-04-21T19:13:23.513566Z","iopub.status.idle":"2024-04-21T19:13:23.523221Z","shell.execute_reply.started":"2024-04-21T19:13:23.513537Z","shell.execute_reply":"2024-04-21T19:13:23.522383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Making the dataloader with the new csv file and showing three images for one of the batches","metadata":{}},{"cell_type":"code","source":"dls = datablock.dataloaders(combined_df, bs=32)\ndls.show_batch(nrows=3, ncols=1)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T19:13:23.524384Z","iopub.execute_input":"2024-04-21T19:13:23.524674Z","iopub.status.idle":"2024-04-21T19:14:14.564502Z","shell.execute_reply.started":"2024-04-21T19:13:23.524651Z","shell.execute_reply":"2024-04-21T19:14:14.563629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Training the model on out dataset, here we choose to use the resnet18 pre-trained model. For metrics we used the accuracy_multi that will give a accuracy for each condition and we set a threshold of 0,5 so that the model will only say the condition is present if it is 50% or more sure that it is present\n\nUnder we find a learning rate and we get three different options and choose the one that looks the best","metadata":{}},{"cell_type":"code","source":"learn = vision_learner(dls, resnet18, metrics=partial(accuracy_multi, thresh=0.5))\nlr = learn.lr_find(suggest_funcs=(valley, steep, slide))","metadata":{"execution":{"iopub.status.busy":"2024-04-21T19:14:14.565716Z","iopub.execute_input":"2024-04-21T19:14:14.566004Z","iopub.status.idle":"2024-04-21T19:14:25.806812Z","shell.execute_reply.started":"2024-04-21T19:14:14.565980Z","shell.execute_reply":"2024-04-21T19:14:25.805795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In this code, we are using the fastai library along with the Hyperopt package to perform hyperparameter tuning for a deep learning model. We define a training and validation function using fastai, specify a hyperparameter search space including learning rate, number of layers, and batch size, and then utilize the Hyperopt fmin function to search for the best hyperparameters within this space. Finally, we train the model using the best hyperparameters found and save the trained model for future use.","metadata":{}},{"cell_type":"code","source":"from fastai.vision.all import *\nfrom hyperopt import hp, fmin, tpe, Trials, STATUS_OK\nfrom functools import partial\n\n\n\n\ndef train_model(params):\n    \n    learn.fine_tune(1, base_lr=params['learning_rate'])\n    loss = learn.recorder.values[-1][0]\n    return {'loss': loss, 'status': STATUS_OK}\n\n   \n    space = {\n    'learning_rate': hp.loguniform('learning_rate', np.log(1e-5), np.log(1e-2)),\n    'num_layers': hp.choice('num_layers', [18, 34, 50]),\n    'batch_size': hp.choice('batch_size', [16, 32, 64]),\n    }\n\n    \n    trials = Trials()\n    best_params = fmin(train_model, space, algo=tpe.suggest, max_evals=10, trials=trials)\n\nprint(\"Beste hyperparametere:\")\nprint(best_params)\n\n\nbest_dls = get_dataloaders(best_params['batch_size'])\nbest_learn = create_model(best_params['num_layers'])\nbest_learn.fine_tune(1, base_lr=best_params['learning_rate'])\nimport pickle\npickle.dump(best_learn, open(\"cheXpertModel\", \"wb\"))\n\n\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-21T19:14:25.808397Z","iopub.execute_input":"2024-04-21T19:14:25.808774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here we present the cases with the higghest loss in our validation set. We get to see what conditions the patient had but also what the model predictet in additon to the different probabilities","metadata":{}},{"cell_type":"code","source":"interp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_top_losses(5, figsize=(15,10))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In the next cells we set up a multilabel condusion matrix to se what conditions the model preforms well at and where the model preforms bad.","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import multilabel_confusion_matrix\n\n# Get predictions\npreds, targs = learn.get_preds()\n\n# Convert predictions to binary using a threshold (e.g., 0.5)\nbinary_preds = preds > 0.5\n\n# Calculate confusion matrix for each label\ncm = multilabel_confusion_matrix(targs, binary_preds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\n\ndef plot_confusion_matrix(cm, label, ax=None):\n    \"\"\"\n    Plots a confusion matrix using seaborn's heatmap.\n    \"\"\"\n    if ax is None:\n        fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)\n    ax.set_title(f'Confusion Matrix for {label}')\n    ax.set_xlabel('Predicted Labels')\n    ax.set_ylabel('True Labels')\n    ax.xaxis.set_ticklabels(['Negative', 'Positive'])\n    ax.yaxis.set_ticklabels(['Negative', 'Positive'])\n\n# Plot the confusion matrix for each label\nfig, axes = plt.subplots(nrows=4, ncols=4, figsize=(20, 20))\naxes = axes.flatten()\nfor i, label in enumerate(chexnet_targets):\n    plot_confusion_matrix(cm[i], label, ax=axes[i])\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def grad_cam(learn, x, class_id=None):\n    # Get the model's last convolutional layer\n    target_layer = learn.model[0][-1]\n    \n    # Hook the feature extractor\n    features = {}\n    def get_features_hook(module, input, output):\n        features[\"conv_features\"] = output.detach()\n    \n    handle_features = target_layer.register_forward_hook(get_features_hook)\n    \n    # Hook for the gradients\n    gradients = {}\n    def get_gradients_hook(module, grad_input, grad_output):\n        gradients[\"conv_gradients\"] = grad_output[0].detach()\n    \n    handle_gradients = target_layer.register_backward_hook(get_gradients_hook)\n    \n    # Forward pass\n    output = learn.model.eval()(x)\n    if class_id is None:\n        class_id = output.argmax(dim=1).item()\n    \n    # Zero gradients\n    learn.model.zero_grad()\n    \n    # Backward pass for the selected class\n    target = output[:, class_id]\n    target.backward()\n    \n    # Get the features and gradients\n    conv_features = features[\"conv_features\"]\n    conv_gradients = gradients[\"conv_gradients\"]\n    \n    # Pool the gradients across the channels\n    pooled_gradients = torch.mean(conv_gradients, dim=[0, 2, 3])\n    \n    # Weight the channels by corresponding gradients\n    for i in range(conv_features.shape[1]):\n        conv_features[:, i, :, :] *= pooled_gradients[i]\n    \n    # Average the channels of the features\n    heatmap = torch.mean(conv_features, dim=1).squeeze()\n    heatmap = np.maximum(heatmap.cpu().numpy(), 0)\n    heatmap /= np.max(heatmap)\n    \n    # Cleanup hooks\n    handle_features.remove()\n    handle_gradients.remove()\n    \n    return heatmap\n\n\ndef plot_heatmap(heatmap, ax, alpha=0.6):\n    img = TensorImage(dls.train.decode((x,))[0][0])  # Decode to get the image\n    img.show(ctx=ax)  # Show the image\n    ax.imshow(heatmap, alpha=alpha, extent=(0, 224, 224, 0),\n              interpolation='bilinear', cmap='magma')\n\n# Usage\nx, _ = dls.one_batch()\nx = x[0].unsqueeze(0).cuda()  # Use the first image of the batch and ensure it's on GPU\nclass_id = None  # Auto-select the class based on model prediction or specify it\n\nheatmap = grad_cam(learn, x, class_id=class_id)\n\n_, ax = plt.subplots()\nplot_heatmap(heatmap, ax)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def grad_cam_batch(learn, xb, class_ids=None):\n    \"\"\"\n    Generate Grad-CAM heatmaps for a batch of images.\n    \n    Args:\n    learn (Learner): The fastai learner with a convolutional model.\n    xb (Tensor): A batch of images, expected shape [N, C, H, W].\n    class_ids (list of int, optional): List of class IDs for which to generate the Grad-CAM.\n        If None, the class with the highest output score is used for each image.\n    \n    Returns:\n    List[Tensor]: A list of heatmaps for each image in the batch.\n    \"\"\"\n    # Ensure model is in evaluation mode and move input to same device as model\n    m = learn.model.eval()\n    xb = xb.to(learn.dls.device)\n\n    # Hook the feature extractor\n    features = {}\n    def hook_features(module, input, output):\n        features['conv_features'] = output.detach()\n\n    # Hook the gradients\n    gradients = {}\n    def hook_gradients(module, grad_in, grad_out):\n        gradients['conv_gradients'] = grad_out[0].detach()\n\n    # Register hooks on the last convolutional layer\n    hook_f = m[0][-1].register_forward_hook(hook_features)\n    hook_b = m[0][-1].register_backward_hook(hook_gradients)\n\n    # Forward pass to get model predictions\n    preds = m(xb)\n    if class_ids is None:\n        # If no class IDs provided, use the class with the highest output score\n        class_ids = preds.argmax(dim=1).tolist()\n\n    heatmaps = []\n    for i, class_id in enumerate(class_ids):\n        one_hot = torch.zeros_like(preds[i])\n        one_hot[class_id] = 1\n        preds[i].backward(one_hot, retain_graph=True if i < len(class_ids)-1 else False)\n\n        # Get features and gradients for the current image\n        conv_features = features['conv_features'][i].unsqueeze(0)\n        conv_gradients = gradients['conv_gradients'][i].unsqueeze(0)\n\n        # Pool the gradients across the channels and weight the channels\n        pooled_gradients = torch.mean(conv_gradients, dim=[0, 2, 3])\n        weighted_features = torch.zeros_like(conv_features)\n        for j in range(conv_features.shape[1]):\n            weighted_features[:, j, :, :] = conv_features[:, j, :, :] * pooled_gradients[j]\n\n        # Generate heatmap by averaging across channels and applying ReLU\n        heatmap = torch.mean(weighted_features, dim=1).squeeze()\n        heatmap = F.relu(heatmap)\n        heatmap /= torch.max(heatmap)\n        heatmaps.append(heatmap.cpu())\n\n    # Remove hooks\n    hook_f.remove()\n    hook_b.remove()\n\n    return heatmaps, class_ids\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_batch_with_heatmaps(dls, xb, heatmaps, class_ids):\n    \"\"\"\n    Plots a batch of images with their corresponding Grad-CAM heatmaps.\n    \n    Args:\n    dls (DataLoaders): The fastai dataloaders, used for decoding batch.\n    xb (Tensor): The batch of images.\n    heatmaps (list of Tensor): A list of heatmaps corresponding to xb.\n    \"\"\"\n    \n    nrows = len(xb)\n    ncols = 2  # For each row: [Original Image, Heatmap]\n    fig, axs = plt.subplots(nrows=nrows, ncols=ncols, figsize=(ncols*5, nrows*5))\n    \n    for i in range(nrows):\n        # Decode and show original image\n        img = dls.train.decode((xb[i:i+1],))[0][0]\n        img.show(ctx=axs[i, 0] if nrows > 1 else axs[0])\n        axs[i, 0].set_title('Original Image')\n        \n        # Show heatmap\n        axs[i, 1].imshow(img.permute(1, 2, 0).cpu().numpy())\n        axs[i, 1].imshow(heatmaps[i], alpha=0.5, extent=(0, img.shape[2], img.shape[1], 0),\n                         cmap='jet')\n        # Use class_id for the title if available, can be replaced with class names if you have a mapping\n        class_name = dls.vocab[class_ids[i]]\n        axs[i, 1].set_title(f'Grad-CAM: Class {class_name}')\n    \n    plt.tight_layout()\n    plt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get a batch of images\nxb, _ = dls.one_batch()\n\n# Generate class IDs if you have specific targets, else None to use the highest scoring class\nclass_ids = None  # Example: [0, 1, 2] for the first three classes, if specific classes are targeted\n\n# Generate heatmaps\nheatmaps, class_ids = grad_cam_batch(learn, xb[:3], class_ids=class_ids)  # Using the first 3 images of the batch\n\n# Visualize\nplot_batch_with_heatmaps(dls, xb[:3], heatmaps, class_ids)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle\npickle.dump(learn, open(\"cheXpertModel\", \"wb\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_loaded = pickle.load(open(\"cheXpertModel\", \"rb\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"interp = ClassificationInterpretation.from_learner(model_loaded)\ninterp.plot_top_losses(5, figsize=(15,10))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}